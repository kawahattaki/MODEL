üìÅ Application d'√âvaluation de Mod√®les de Classification d'Images

## üéØ Aper√ßu et Objectifs du Projet

Ce projet est une application de d√©monstration interactive d√©velopp√©e avec **Streamlit** pour la classification d'images de fleurs (cinq cat√©gories : *daisy*, *dandelion*, *rose*, *sunflower*, *tulip*).

L'objectif principal est de **comparer trois approches d'entra√Ænement de mod√®les** sur le m√™me jeu de donn√©es, en √©valuant leurs performances via des m√©triques et des visualisations d√©taill√©es, tout en offrant une interface utilisateur pour la pr√©diction en temps r√©el.

### Composants Cl√©s
Le projet est structur√© autour des √©l√©ments suivants pour garantir l'interactivit√©, la performance et l'analyse :

Interface Utilisateur : D√©velopp√©e avec Streamlit, elle sert d'application web interactive pour l'√©valuation des mod√®les, la visualisation des m√©triques et la pr√©diction en temps r√©el.

Mod√®le 1 (Keras - Transfer Learning) : Un mod√®le de classification d'images bas√© sur le Transfer Learning (Transfert d'Apprentissage), utilisant potentiellement une architecture pr√©-entra√Æn√©e (comme VGG16 ou ResNet), pour tirer parti des connaissances acquises sur de grands jeux de donn√©es.

Mod√®le 2 (Keras - Mod√®le S√©quentiel) : Un mod√®le Keras classique entra√Æn√© √† partir de z√©ro (Custom) sur le jeu de donn√©es, permettant de comparer les performances avec l'approche de Transfer Learning.

Mod√®le 3 (Scikit-learn - Classifieur Traditionnel) : Un mod√®le d'apprentissage automatique traditionnel (par exemple, Support Vector Machine ou Random Forest) qui op√®re sur des features (caract√©ristiques) extraites par un r√©seau de neurones ou une autre technique de feature engineering.

Historique & Mod√®les S√©rialis√©s : Utilisation de Git pour le suivi de version du code, et de fichiers Keras H5 et Pickle (.pkl) pour s√©rialiser et charger rapidement les trois mod√®les entra√Æn√©s sans n√©cessiter un nouvel entra√Ænement.

Documentation Technique : R√©dig√©e avec Sphinx en format reStructuredText, elle fournit un corpus complet sur l'architecture du code, la m√©thodologie d'entra√Ænement et les r√©sultats d√©taill√©s.

## ‚öôÔ∏è Configuration du Projet et Installation

### Pr√©requis

  * Python 3.8+
  * Git

### 1\. Clonage du D√©p√¥t

Clonez le projet sur votre machine locale :

```bash
git clone https://github.com/<votre_nom_github>/app_classification.git
cd app_classification
```

### 2\. Configuration de l'Environnement

Nous utilisons un environnement virtuel pour isoler les d√©pendances.

```bash
# Cr√©e l'environnement virtuel (.venv)
python -m venv .venv

# Active l'environnement virtuel
# Windows PowerShell :
.\.venv\Scripts\activate
# Linux/macOS :
source .venv/bin/activate
```

### 3\. Installation des D√©pendances

Installez toutes les biblioth√®ques requises, y compris TensorFlow, Scikit-learn, et Streamlit :

```bash
pip install -r requirements.txt
```

-----

## üíª Utilisation de l'Application

### D√©marrage

Lancez l'application Streamlit depuis la racine du projet (`app_classification/`) :

```bash
streamlit run app.py
```

L'interface sera accessible via votre navigateur √† l'adresse `http://localhost:8501`.

### Fonctionnalit√©s

1.  **Pr√©diction en Temps R√©el** : Permet de glisser-d√©poser une image. Les trois mod√®les retournent imm√©diatement leurs pr√©dictions (classe pr√©dite et niveau de confiance).
2.  **Visualisation de l'√âvaluation** : La page principale affiche les matrices de confusion d√©taill√©es pour chaque mod√®le, permettant une analyse rapide des faux positifs et faux n√©gatifs.
3.  **Param√®tres du Mod√®le** : Le panneau lat√©ral permet d'ajuster certains param√®tres (comme le ratio de split des donn√©es), bien que les mod√®les finaux soient pr√©-entra√Æn√©s pour la d√©mo.

-----

## üóÉÔ∏è Structure D√©taill√©e des Donn√©es et Mod√®les

| Chemin | Contenu | Notes de Version |
| :--- | :--- | :--- |
| `app.py` | Logique de l'interface Streamlit. | G√®re les chargements des mod√®les et l'affichage des r√©sultats. |
| `create_models.py` | Script d'entra√Ænement. | Utilis√© initialement pour g√©n√©rer les fichiers dans `models/`. |
| `models/tm_model.h5` | Mod√®le **Keras** (Transfer Learning). | Fichier binaire HDF5. Charg√© via `tf.keras.models.load_model()`. |
| `models/notebook1.pkl` | Mod√®le **Keras S√©quentiel** (Custom). | Fichier binaire Pickle. N√©cessite l'environnement TensorFlow/Keras pour √™tre utilis√©. |
| `models/notebook3.pkl` | Mod√®le **Scikit-learn**. | Fichier binaire Pickle. (Ex: un classifieur bas√© sur des *features* extraites par un autre r√©seau). |
| `.gitignore` | Exclusions Git. | Exclut tous les fichiers mod√®les lourds (`*.h5`, `*.pkl`) **si** la politique du d√©p√¥t l'exige (actuellement, ces fichiers sont exclus de l'historique volumineux initial mais peuvent √™tre pr√©sents pour des raisons de d√©ploiement). |

-----

## üìö Documentation Technique

Une documentation compl√®te a √©t√© r√©dig√©e avec **Sphinx** pour accompagner ce projet. Elle inclut :

  * L'architecture logicielle de l'application.
  * La m√©thodologie d'extraction des donn√©es.
  * Les d√©tails de l'entra√Ænement et des hyperparam√®tres pour chaque mod√®le.
  * Les r√©sultats de performance complets.

La documentation est accessible localement en ouvrant le fichier :

```
docs/_build/html/index.html
```

-----

## üîí Gestion des Contribuables (Git)

Ce d√©p√¥t est configur√© pour un workflow **Fork & Pull Request**.

  * Pour contribuer : Forkez le d√©p√¥t, cr√©ez une nouvelle branche pour vos modifications, puis soumettez une Pull Request vers la branche `main` du d√©p√¥t principal.
  * L'historique Git a √©t√© nettoy√© des fichiers volumineux pour garantir la rapidit√© du clonage et du travail collaboratif.

-----

## üë§ Auteur

  * **Auteur** : **hattaki**
  * **Ann√©e** : 2025
